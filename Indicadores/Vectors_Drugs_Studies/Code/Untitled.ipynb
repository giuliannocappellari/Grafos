{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import spacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dados_treino = pd.read_csv(\"../Data/resultado_drogas.csv\", encoding = 'latin-1', sep = ';',dtype='unicode')\r\n",
    "dados_treino.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAVE_OBJETO</th>\n",
       "      <th>ANO_OCOR</th>\n",
       "      <th>NRO_OCOR</th>\n",
       "      <th>NRO_INT_TIPO_OBJETO</th>\n",
       "      <th>TXT_TIPO_OBJETO</th>\n",
       "      <th>Cor Predominante</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Peso Total</th>\n",
       "      <th>Peso Unitário</th>\n",
       "      <th>Quantidade de Unidade(s)</th>\n",
       "      <th>Tipo de Embalagem</th>\n",
       "      <th>Unidade de Peso</th>\n",
       "      <th>DESC_PADRAO</th>\n",
       "      <th>RECLASSIFICAÇÃO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>21094581</td>\n",
       "      <td>2019</td>\n",
       "      <td>228</td>\n",
       "      <td>1025</td>\n",
       "      <td>Drogas</td>\n",
       "      <td>Amarelo</td>\n",
       "      <td>Buck Stack 350 vinculado ao codigo OA112488549BR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Frasco(s)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buck stack 350 vinculado ao codigo oa112488549br</td>\n",
       "      <td>Drogas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26629</th>\n",
       "      <td>23075271</td>\n",
       "      <td>2020</td>\n",
       "      <td>274</td>\n",
       "      <td>1025</td>\n",
       "      <td>Drogas</td>\n",
       "      <td>Verde</td>\n",
       "      <td>1 PORÇÃO DE ERVA ESVERDEADA SEMELHANTE MACONHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,00</td>\n",
       "      <td>1</td>\n",
       "      <td>Porção(es)</td>\n",
       "      <td>Grama</td>\n",
       "      <td>1 porcao de erva esverdeada semelhante maconha</td>\n",
       "      <td>Maconha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85529</th>\n",
       "      <td>23061886</td>\n",
       "      <td>2020</td>\n",
       "      <td>3645</td>\n",
       "      <td>756</td>\n",
       "      <td>Cocaína</td>\n",
       "      <td>Branco</td>\n",
       "      <td>10 PORÇÕES DE COCAÍNA, TOTALIZANDO 35 GRAMAS</td>\n",
       "      <td>35,00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Porção(es)</td>\n",
       "      <td>Grama</td>\n",
       "      <td>10 porcoes de cocaina totalizando 35 gramas</td>\n",
       "      <td>Cocaína</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104727</th>\n",
       "      <td>23803633</td>\n",
       "      <td>2021</td>\n",
       "      <td>4429</td>\n",
       "      <td>757</td>\n",
       "      <td>Crack</td>\n",
       "      <td>Marrom</td>\n",
       "      <td>13,10 GRAMAS DE SUBSTANCIA SEMELHANTE A CRACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Porção(es)</td>\n",
       "      <td>Grama</td>\n",
       "      <td>1310 gramas de substancia semelhante a crack</td>\n",
       "      <td>Crack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64349</th>\n",
       "      <td>22295666</td>\n",
       "      <td>2020</td>\n",
       "      <td>2864</td>\n",
       "      <td>756</td>\n",
       "      <td>Cocaína</td>\n",
       "      <td>Cinza</td>\n",
       "      <td>252 pinos de substância semelhante a cocaína p...</td>\n",
       "      <td>170,00</td>\n",
       "      <td>0,07</td>\n",
       "      <td>252</td>\n",
       "      <td>Unidade(s)</td>\n",
       "      <td>Grama</td>\n",
       "      <td>252 pinos de substancia semelhante a cocaina p...</td>\n",
       "      <td>Cocaína</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CHAVE_OBJETO ANO_OCOR NRO_OCOR NRO_INT_TIPO_OBJETO TXT_TIPO_OBJETO  \\\n",
       "4664       21094581     2019      228                1025          Drogas   \n",
       "26629      23075271     2020      274                1025          Drogas   \n",
       "85529      23061886     2020     3645                 756         Cocaína   \n",
       "104727     23803633     2021     4429                 757           Crack   \n",
       "64349      22295666     2020     2864                 756         Cocaína   \n",
       "\n",
       "       Cor Predominante                                          Descrição  \\\n",
       "4664            Amarelo   Buck Stack 350 vinculado ao codigo OA112488549BR   \n",
       "26629             Verde     1 PORÇÃO DE ERVA ESVERDEADA SEMELHANTE MACONHA   \n",
       "85529            Branco       10 PORÇÕES DE COCAÍNA, TOTALIZANDO 35 GRAMAS   \n",
       "104727           Marrom      13,10 GRAMAS DE SUBSTANCIA SEMELHANTE A CRACK   \n",
       "64349             Cinza  252 pinos de substância semelhante a cocaína p...   \n",
       "\n",
       "       Peso Total Peso Unitário Quantidade de Unidade(s) Tipo de Embalagem  \\\n",
       "4664          NaN           NaN                        1         Frasco(s)   \n",
       "26629         NaN         13,00                        1        Porção(es)   \n",
       "85529       35,00           NaN                       10        Porção(es)   \n",
       "104727        NaN           NaN                        0        Porção(es)   \n",
       "64349      170,00          0,07                      252        Unidade(s)   \n",
       "\n",
       "       Unidade de Peso                                        DESC_PADRAO  \\\n",
       "4664               NaN   buck stack 350 vinculado ao codigo oa112488549br   \n",
       "26629            Grama     1 porcao de erva esverdeada semelhante maconha   \n",
       "85529            Grama        10 porcoes de cocaina totalizando 35 gramas   \n",
       "104727           Grama       1310 gramas de substancia semelhante a crack   \n",
       "64349            Grama  252 pinos de substancia semelhante a cocaina p...   \n",
       "\n",
       "       RECLASSIFICAÇÃO  \n",
       "4664            Drogas  \n",
       "26629          Maconha  \n",
       "85529          Cocaína  \n",
       "104727           Crack  \n",
       "64349          Cocaína  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nlp = spacy.load('pt_core_news_lg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "def trata_textos(doc):\r\n",
    "    tokens_validos = []\r\n",
    "    for token in doc:\r\n",
    "        e_valido = not token.is_stop and token.is_alpha\r\n",
    "        if e_valido:\r\n",
    "            tokens_validos.append(token.text)\r\n",
    "\r\n",
    "    if len(tokens_validos) > 2:\r\n",
    "        return  \" \".join(tokens_validos)\r\n",
    "\r\n",
    "\r\n",
    "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa de Deus!\"\r\n",
    "doc = nlp(texto)\r\n",
    "trata_textos(doc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Rio Janeiro cidade maravilhosa Deus'"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "textos_para_tratamento = (str(descricoes).lower() for descricoes in dados_treino[\"Descrição\"])\r\n",
    "textos_para_tratamento"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x000002A74FC41D60>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from time import time\r\n",
    "\r\n",
    "t0 = time()\r\n",
    "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\r\n",
    "                                                        batch_size = 120000,\r\n",
    "                                                        n_process = -1)]\r\n",
    "\r\n",
    "tf = time() - t0\r\n",
    "\r\n",
    "print(tf/60)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7.065493321418762\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "titulos_tratados = pd.DataFrame({\"descricao\": textos_tratados})\r\n",
    "titulos_tratados.sample(20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>apreendido cigarros substância semelhante maco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68479</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111628</th>\n",
       "      <td>porções substância semelhante crack pesando ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80567</th>\n",
       "      <td>bucha pó branco semelhante cocaina peso gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>substãncia semelhante cocaína</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32472</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65254</th>\n",
       "      <td>aproximadamente gramas maconha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52758</th>\n",
       "      <td>gramas substância semelhante maconha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84843</th>\n",
       "      <td>tijolo maconha pesando gramas aproximadamente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>pinos pequenos substancia semelhante cocaina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51906</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>porção substância características maconha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82411</th>\n",
       "      <td>pinos contendo substancia semelhante cocaina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74950</th>\n",
       "      <td>tijolos maconha peso total embalagem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74213</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34242</th>\n",
       "      <td>porção substância cor branca características c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96539</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32784</th>\n",
       "      <td>porções substância similar cocaína</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102617</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46078</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                descricao\n",
       "3396    apreendido cigarros substância semelhante maco...\n",
       "68479                                                None\n",
       "111628  porções substância semelhante crack pesando ap...\n",
       "80567          bucha pó branco semelhante cocaina peso gr\n",
       "23468                       substãncia semelhante cocaína\n",
       "32472                                                None\n",
       "65254                      aproximadamente gramas maconha\n",
       "52758                gramas substância semelhante maconha\n",
       "84843       tijolo maconha pesando gramas aproximadamente\n",
       "2386         pinos pequenos substancia semelhante cocaina\n",
       "51906                                                None\n",
       "6857            porção substância características maconha\n",
       "82411        pinos contendo substancia semelhante cocaina\n",
       "74950                tijolos maconha peso total embalagem\n",
       "74213                                                None\n",
       "34242   porção substância cor branca características c...\n",
       "96539                                                None\n",
       "32784                  porções substância similar cocaína\n",
       "102617                                               None\n",
       "46078                                                None"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from gensim.models import Word2Vec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#sg = pois queremos o modelo cbow e não skipGram\r\n",
    "#window = quantas palavras ele considera antes e quantas depois\r\n",
    "#vector_size= dimenões do meu vetor\r\n",
    "#min_count = minimo de palavras presentes\r\n",
    "#Valor que vai determinar qual a taxa que estou aprendendo e reduzindo minha função de custo\r\n",
    "#Min alpha o valor da distancia que a função de custo vai decair\r\n",
    "w2v_modelo = Word2Vec(sg = 0,\r\n",
    "                      window = 2,\r\n",
    "                      vector_size = 300,\r\n",
    "                      min_count = 0,\r\n",
    "                      alpha = 0.03,\r\n",
    "                      min_alpha = 0.007)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "w2v_modeblo"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x2a76b92e670>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(len(titulos_tratados))\r\n",
    "\r\n",
    "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\r\n",
    "\r\n",
    "print(len(titulos_tratados))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "113231\n",
      "51280\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "lista_lista_tokens = [desc.split(' ') for desc in titulos_tratados.descricao]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "w2v_modelo.build_vocab(lista_lista_tokens)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import logging\r\n",
    "\r\n",
    "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level = logging.INFO)\r\n",
    "\r\n",
    "w2v_modelo = Word2Vec(sg = 0,\r\n",
    "                      window = 5,\r\n",
    "                      vector_size = 300,\r\n",
    "                      min_count = 0,\r\n",
    "                      alpha = 0.03,\r\n",
    "                      min_alpha = 0.007)\r\n",
    "\r\n",
    "w2v_modelo.build_vocab(lista_lista_tokens, progress_per = 5000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-30 15:15:38,979 : - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.03)', 'datetime': '2021-09-30T15:15:38.979372', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n",
      "2021-09-30 15:15:38,981 : - collecting all words and their counts\n",
      "2021-09-30 15:15:38,982 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-30 15:15:38,997 : - PROGRESS: at sentence #5000, processed 29277 words, keeping 1822 word types\n",
      "2021-09-30 15:15:39,011 : - PROGRESS: at sentence #10000, processed 60106 words, keeping 2813 word types\n",
      "2021-09-30 15:15:39,022 : - PROGRESS: at sentence #15000, processed 92131 words, keeping 3740 word types\n",
      "2021-09-30 15:15:39,035 : - PROGRESS: at sentence #20000, processed 125251 words, keeping 4473 word types\n",
      "2021-09-30 15:15:39,051 : - PROGRESS: at sentence #25000, processed 155609 words, keeping 5174 word types\n",
      "2021-09-30 15:15:39,067 : - PROGRESS: at sentence #30000, processed 188111 words, keeping 5799 word types\n",
      "2021-09-30 15:15:39,084 : - PROGRESS: at sentence #35000, processed 222608 words, keeping 6350 word types\n",
      "2021-09-30 15:15:39,100 : - PROGRESS: at sentence #40000, processed 256109 words, keeping 6926 word types\n",
      "2021-09-30 15:15:39,114 : - PROGRESS: at sentence #45000, processed 289303 words, keeping 7419 word types\n",
      "2021-09-30 15:15:39,134 : - PROGRESS: at sentence #50000, processed 322285 words, keeping 7878 word types\n",
      "2021-09-30 15:15:39,138 : - collected 8018 word types from a corpus of 330737 raw words and 51280 sentences\n",
      "2021-09-30 15:15:39,139 : - Creating a fresh vocabulary\n",
      "2021-09-30 15:15:39,206 : - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8018 unique words (100.0%% of original 8018, drops 0)', 'datetime': '2021-09-30T15:15:39.206858', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-30 15:15:39,206 : - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 330737 word corpus (100.0%% of original 330737, drops 0)', 'datetime': '2021-09-30T15:15:39.206858', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-30 15:15:39,302 : - deleting the raw counts dictionary of 8018 items\n",
      "2021-09-30 15:15:39,311 : - sample=0.001 downsamples 56 most-common words\n",
      "2021-09-30 15:15:39,312 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 168293.1755926243 word corpus (50.9%% of prior 330737)', 'datetime': '2021-09-30T15:15:39.312576', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-30 15:15:39,420 : - estimated required memory for 8018 words and 300 dimensions: 23252200 bytes\n",
      "2021-09-30 15:15:39,421 : - resetting layer weights\n",
      "2021-09-30 15:15:39,435 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-30T15:15:39.435754', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dir(w2v_modelo)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_corpus_sanity',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_epoch',\n",
       " '_do_train_job',\n",
       " '_get_next_alpha',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_specials',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_scan_vocab',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_train_epoch_corpusfile',\n",
       " '_worker_loop',\n",
       " '_worker_loop_corpusfile',\n",
       " 'add_lifecycle_event',\n",
       " 'add_null_word',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'cbow_mean',\n",
       " 'comment',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'corpus_total_words',\n",
       " 'create_binary_tree',\n",
       " 'cum_table',\n",
       " 'effective_min_count',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'get_latest_training_loss',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'init_sims',\n",
       " 'init_weights',\n",
       " 'layer1_size',\n",
       " 'lifecycle_events',\n",
       " 'load',\n",
       " 'make_cum_table',\n",
       " 'max_final_vocab',\n",
       " 'max_vocab_size',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'negative',\n",
       " 'ns_exponent',\n",
       " 'null_word',\n",
       " 'predict_output_word',\n",
       " 'prepare_vocab',\n",
       " 'prepare_weights',\n",
       " 'random',\n",
       " 'raw_vocab',\n",
       " 'reset_from',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'scan_vocab',\n",
       " 'score',\n",
       " 'seed',\n",
       " 'seeded_vector',\n",
       " 'sg',\n",
       " 'shrink_windows',\n",
       " 'sorted_vocab',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'update_weights',\n",
       " 'vector_size',\n",
       " 'window',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "w2v_modelo.corpus_count"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "51280"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "w2v_modelo.train(lista_lista_tokens, \r\n",
    "                 total_examples=w2v_modelo.corpus_count,\r\n",
    "                 epochs=30)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-30 15:15:50,290 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 8018 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-30T15:15:50.290624', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n",
      "2021-09-30 15:15:50,852 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:50,877 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:50,888 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:50,889 : - EPOCH - 1 : training on 330737 raw words (168114 effective words) took 0.5s, 314193 effective words/s\n",
      "2021-09-30 15:15:51,464 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:51,476 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:51,492 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:51,492 : - EPOCH - 2 : training on 330737 raw words (168383 effective words) took 0.6s, 285149 effective words/s\n",
      "2021-09-30 15:15:52,021 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:52,040 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:52,044 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:52,044 : - EPOCH - 3 : training on 330737 raw words (168684 effective words) took 0.5s, 312377 effective words/s\n",
      "2021-09-30 15:15:52,614 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:52,615 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:52,623 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:52,624 : - EPOCH - 4 : training on 330737 raw words (168249 effective words) took 0.6s, 298275 effective words/s\n",
      "2021-09-30 15:15:53,231 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:53,234 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:53,260 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:53,261 : - EPOCH - 5 : training on 330737 raw words (168159 effective words) took 0.6s, 268996 effective words/s\n",
      "2021-09-30 15:15:53,784 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:53,794 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:53,795 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:53,795 : - EPOCH - 6 : training on 330737 raw words (168360 effective words) took 0.5s, 328207 effective words/s\n",
      "2021-09-30 15:15:54,306 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:54,308 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:54,312 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:54,312 : - EPOCH - 7 : training on 330737 raw words (168493 effective words) took 0.5s, 334160 effective words/s\n",
      "2021-09-30 15:15:54,830 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:54,855 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:54,860 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:54,861 : - EPOCH - 8 : training on 330737 raw words (168441 effective words) took 0.5s, 313703 effective words/s\n",
      "2021-09-30 15:15:55,372 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:55,373 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:55,375 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:55,376 : - EPOCH - 9 : training on 330737 raw words (168194 effective words) took 0.5s, 335974 effective words/s\n",
      "2021-09-30 15:15:55,828 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:55,835 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:55,842 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:55,843 : - EPOCH - 10 : training on 330737 raw words (168088 effective words) took 0.5s, 370854 effective words/s\n",
      "2021-09-30 15:15:56,339 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:56,356 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:56,359 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:56,360 : - EPOCH - 11 : training on 330737 raw words (168187 effective words) took 0.5s, 332146 effective words/s\n",
      "2021-09-30 15:15:56,872 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:56,877 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:56,886 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:56,888 : - EPOCH - 12 : training on 330737 raw words (168234 effective words) took 0.5s, 329127 effective words/s\n",
      "2021-09-30 15:15:57,351 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:57,359 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:57,363 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:57,364 : - EPOCH - 13 : training on 330737 raw words (167994 effective words) took 0.5s, 363395 effective words/s\n",
      "2021-09-30 15:15:57,867 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:57,878 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:57,879 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:57,879 : - EPOCH - 14 : training on 330737 raw words (168497 effective words) took 0.5s, 338168 effective words/s\n",
      "2021-09-30 15:15:58,393 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:58,395 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:58,404 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:58,405 : - EPOCH - 15 : training on 330737 raw words (168170 effective words) took 0.5s, 329894 effective words/s\n",
      "2021-09-30 15:15:58,878 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:58,883 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:58,890 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:58,891 : - EPOCH - 16 : training on 330737 raw words (168500 effective words) took 0.5s, 356442 effective words/s\n",
      "2021-09-30 15:15:59,357 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:59,366 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:59,371 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:59,372 : - EPOCH - 17 : training on 330737 raw words (168184 effective words) took 0.5s, 357605 effective words/s\n",
      "2021-09-30 15:15:59,825 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:15:59,841 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:15:59,843 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:15:59,844 : - EPOCH - 18 : training on 330737 raw words (168353 effective words) took 0.5s, 365871 effective words/s\n",
      "2021-09-30 15:16:00,343 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:00,358 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:00,377 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:00,378 : - EPOCH - 19 : training on 330737 raw words (168246 effective words) took 0.5s, 326724 effective words/s\n",
      "2021-09-30 15:16:00,889 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:00,897 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:00,914 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:00,916 : - EPOCH - 20 : training on 330737 raw words (168302 effective words) took 0.5s, 329600 effective words/s\n",
      "2021-09-30 15:16:01,431 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:01,435 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:01,457 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:01,459 : - EPOCH - 21 : training on 330737 raw words (168152 effective words) took 0.5s, 318073 effective words/s\n",
      "2021-09-30 15:16:01,927 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:01,942 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:01,946 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:01,946 : - EPOCH - 22 : training on 330737 raw words (168320 effective words) took 0.5s, 354179 effective words/s\n",
      "2021-09-30 15:16:02,396 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:02,408 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:02,414 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:02,415 : - EPOCH - 23 : training on 330737 raw words (168511 effective words) took 0.5s, 369249 effective words/s\n",
      "2021-09-30 15:16:02,883 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:02,902 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:02,909 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:02,910 : - EPOCH - 24 : training on 330737 raw words (168326 effective words) took 0.5s, 348447 effective words/s\n",
      "2021-09-30 15:16:03,376 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:03,381 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:03,389 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:03,389 : - EPOCH - 25 : training on 330737 raw words (168068 effective words) took 0.5s, 359179 effective words/s\n",
      "2021-09-30 15:16:03,915 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:03,924 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:03,929 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:03,930 : - EPOCH - 26 : training on 330737 raw words (168657 effective words) took 0.5s, 318861 effective words/s\n",
      "2021-09-30 15:16:04,389 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:04,391 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:04,403 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:04,404 : - EPOCH - 27 : training on 330737 raw words (168003 effective words) took 0.5s, 363601 effective words/s\n",
      "2021-09-30 15:16:04,967 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:04,972 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:04,977 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:04,978 : - EPOCH - 28 : training on 330737 raw words (168482 effective words) took 0.6s, 299865 effective words/s\n",
      "2021-09-30 15:16:05,424 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:05,433 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:05,438 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:05,439 : - EPOCH - 29 : training on 330737 raw words (168042 effective words) took 0.4s, 374291 effective words/s\n",
      "2021-09-30 15:16:05,892 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:05,907 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:05,914 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:05,915 : - EPOCH - 30 : training on 330737 raw words (168288 effective words) took 0.5s, 362431 effective words/s\n",
      "2021-09-30 15:16:05,916 : - Word2Vec lifecycle event {'msg': 'training on 9922110 raw words (5048681 effective words) took 15.6s, 323149 effective words/s', 'datetime': '2021-09-30T15:16:05.916052', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5048681, 9922110)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "w2v_modelo.wv.most_similar(\"cocaina\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('cocaína', 0.7129589319229126),\n",
       " ('cocaíca', 0.4762324094772339),\n",
       " ('cocaiina', 0.4380021393299103),\n",
       " ('cocaíana', 0.436846524477005),\n",
       " ('eppenford', 0.42361265420913696),\n",
       " ('cocacina', 0.40337687730789185),\n",
       " ('cacaína', 0.3977382183074951),\n",
       " ('cacaina', 0.37509796023368835),\n",
       " ('cocaine', 0.3686312735080719),\n",
       " ('côr', 0.3666975200176239)]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "w2v_modelo.wv.most_similar(\"maconha\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('prensada', 0.44905149936676025),\n",
       " ('artesanais', 0.44679534435272217),\n",
       " ('erva', 0.44316309690475464),\n",
       " ('maconhaha', 0.4345993399620056),\n",
       " ('maconhaa', 0.43023690581321716),\n",
       " ('maconhanha', 0.4228149354457855),\n",
       " ('macona', 0.4175446331501007),\n",
       " ('esverdeada', 0.4125462472438812),\n",
       " ('machonha', 0.41027700901031494),\n",
       " ('amaconha', 0.4097497761249542)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "w2v_modelo.wv.most_similar(\"crak\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('crack', 0.7438182830810547),\n",
       " ('carck', 0.5109866261482239),\n",
       " ('ckack', 0.5034031271934509),\n",
       " ('crck', 0.4934164583683014),\n",
       " ('ptotalizando', 0.42175883054733276),\n",
       " ('inteira', 0.4157085418701172),\n",
       " ('papela', 0.4139401316642761),\n",
       " ('vintee', 0.40566036105155945),\n",
       " ('crakc', 0.40253958106040955),\n",
       " ('pap', 0.40126633644104004)]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import logging\r\n",
    "\r\n",
    "w2v_modelo_sg = Word2Vec(sg = 1,\r\n",
    "                      window = 5,\r\n",
    "                      vector_size = 300,\r\n",
    "                      min_count = 0,\r\n",
    "                      alpha = 0.03,\r\n",
    "                      min_alpha = 0.007)\r\n",
    "\r\n",
    "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per = 5000)\r\n",
    "\r\n",
    "w2v_modelo_sg.train(lista_lista_tokens, \r\n",
    "                 total_examples=w2v_modelo_sg.corpus_count,\r\n",
    "                 epochs=30)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-30 15:16:28,919 : - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.03)', 'datetime': '2021-09-30T15:16:28.919095', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n",
      "2021-09-30 15:16:28,921 : - collecting all words and their counts\n",
      "2021-09-30 15:16:28,922 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-30 15:16:28,933 : - PROGRESS: at sentence #5000, processed 29277 words, keeping 1822 word types\n",
      "2021-09-30 15:16:28,941 : - PROGRESS: at sentence #10000, processed 60106 words, keeping 2813 word types\n",
      "2021-09-30 15:16:28,955 : - PROGRESS: at sentence #15000, processed 92131 words, keeping 3740 word types\n",
      "2021-09-30 15:16:28,968 : - PROGRESS: at sentence #20000, processed 125251 words, keeping 4473 word types\n",
      "2021-09-30 15:16:28,979 : - PROGRESS: at sentence #25000, processed 155609 words, keeping 5174 word types\n",
      "2021-09-30 15:16:28,990 : - PROGRESS: at sentence #30000, processed 188111 words, keeping 5799 word types\n",
      "2021-09-30 15:16:29,002 : - PROGRESS: at sentence #35000, processed 222608 words, keeping 6350 word types\n",
      "2021-09-30 15:16:29,019 : - PROGRESS: at sentence #40000, processed 256109 words, keeping 6926 word types\n",
      "2021-09-30 15:16:29,037 : - PROGRESS: at sentence #45000, processed 289303 words, keeping 7419 word types\n",
      "2021-09-30 15:16:29,051 : - PROGRESS: at sentence #50000, processed 322285 words, keeping 7878 word types\n",
      "2021-09-30 15:16:29,059 : - collected 8018 word types from a corpus of 330737 raw words and 51280 sentences\n",
      "2021-09-30 15:16:29,060 : - Creating a fresh vocabulary\n",
      "2021-09-30 15:16:29,124 : - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8018 unique words (100.0%% of original 8018, drops 0)', 'datetime': '2021-09-30T15:16:29.124545', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-30 15:16:29,124 : - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 330737 word corpus (100.0%% of original 330737, drops 0)', 'datetime': '2021-09-30T15:16:29.124545', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-30 15:16:29,219 : - deleting the raw counts dictionary of 8018 items\n",
      "2021-09-30 15:16:29,220 : - sample=0.001 downsamples 56 most-common words\n",
      "2021-09-30 15:16:29,221 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 168293.1755926243 word corpus (50.9%% of prior 330737)', 'datetime': '2021-09-30T15:16:29.221924', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-30 15:16:29,335 : - estimated required memory for 8018 words and 300 dimensions: 23252200 bytes\n",
      "2021-09-30 15:16:29,336 : - resetting layer weights\n",
      "2021-09-30 15:16:29,349 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-30T15:16:29.349066', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'build_vocab'}\n",
      "2021-09-30 15:16:29,350 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 8018 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-30T15:16:29.350066', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n",
      "2021-09-30 15:16:30,368 : - EPOCH 1 - PROGRESS: at 90.83% examples, 152092 words/s, in_qsize 4, out_qsize 0\n",
      "2021-09-30 15:16:30,411 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:30,436 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:30,458 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:30,459 : - EPOCH - 1 : training on 330737 raw words (168114 effective words) took 1.1s, 153267 effective words/s\n",
      "2021-09-30 15:16:31,501 : - EPOCH 2 - PROGRESS: at 82.05% examples, 134675 words/s, in_qsize 5, out_qsize 0\n",
      "2021-09-30 15:16:31,605 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:31,621 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:31,650 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:31,651 : - EPOCH - 2 : training on 330737 raw words (168397 effective words) took 1.2s, 142978 effective words/s\n",
      "2021-09-30 15:16:32,653 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:32,658 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:32,672 : - EPOCH 3 - PROGRESS: at 100.00% examples, 167330 words/s, in_qsize 0, out_qsize 1\n",
      "2021-09-30 15:16:32,672 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:32,673 : - EPOCH - 3 : training on 330737 raw words (168439 effective words) took 1.0s, 167100 effective words/s\n",
      "2021-09-30 15:16:33,560 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:33,590 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:33,599 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:33,600 : - EPOCH - 4 : training on 330737 raw words (168240 effective words) took 0.9s, 184178 effective words/s\n",
      "2021-09-30 15:16:34,630 : - EPOCH 5 - PROGRESS: at 93.80% examples, 155211 words/s, in_qsize 3, out_qsize 0\n",
      "2021-09-30 15:16:34,635 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:34,643 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:34,649 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:34,650 : - EPOCH - 5 : training on 330737 raw words (168063 effective words) took 1.0s, 162052 effective words/s\n",
      "2021-09-30 15:16:35,569 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:35,570 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:35,585 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:35,586 : - EPOCH - 6 : training on 330737 raw words (168509 effective words) took 0.9s, 182530 effective words/s\n",
      "2021-09-30 15:16:36,487 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:36,502 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:36,530 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:36,531 : - EPOCH - 7 : training on 330737 raw words (168350 effective words) took 0.9s, 180551 effective words/s\n",
      "2021-09-30 15:16:37,477 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:37,489 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:37,498 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:37,499 : - EPOCH - 8 : training on 330737 raw words (168230 effective words) took 1.0s, 176879 effective words/s\n",
      "2021-09-30 15:16:38,468 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:38,469 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:38,501 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:38,501 : - EPOCH - 9 : training on 330737 raw words (168424 effective words) took 1.0s, 170134 effective words/s\n",
      "2021-09-30 15:16:39,391 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:39,392 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:39,412 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:39,412 : - EPOCH - 10 : training on 330737 raw words (168366 effective words) took 0.9s, 187027 effective words/s\n",
      "2021-09-30 15:16:40,341 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:40,357 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:40,373 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:40,374 : - EPOCH - 11 : training on 330737 raw words (168224 effective words) took 0.9s, 177113 effective words/s\n",
      "2021-09-30 15:16:41,292 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:41,293 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:41,307 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:41,307 : - EPOCH - 12 : training on 330737 raw words (168295 effective words) took 0.9s, 183118 effective words/s\n",
      "2021-09-30 15:16:42,171 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:42,184 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:42,196 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:42,196 : - EPOCH - 13 : training on 330737 raw words (168199 effective words) took 0.9s, 191776 effective words/s\n",
      "2021-09-30 15:16:43,124 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:43,125 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:43,132 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:43,133 : - EPOCH - 14 : training on 330737 raw words (167995 effective words) took 0.9s, 181731 effective words/s\n",
      "2021-09-30 15:16:44,069 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:44,071 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:44,091 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:44,092 : - EPOCH - 15 : training on 330737 raw words (168328 effective words) took 0.9s, 177794 effective words/s\n",
      "2021-09-30 15:16:44,957 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:44,979 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:45,000 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:45,001 : - EPOCH - 16 : training on 330737 raw words (168165 effective words) took 0.9s, 187713 effective words/s\n",
      "2021-09-30 15:16:45,931 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:45,933 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:45,948 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:45,948 : - EPOCH - 17 : training on 330737 raw words (168552 effective words) took 0.9s, 180148 effective words/s\n",
      "2021-09-30 15:16:46,940 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:46,945 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:46,960 : - EPOCH 18 - PROGRESS: at 100.00% examples, 168322 words/s, in_qsize 0, out_qsize 1\n",
      "2021-09-30 15:16:46,961 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:46,962 : - EPOCH - 18 : training on 330737 raw words (168344 effective words) took 1.0s, 168118 effective words/s\n",
      "2021-09-30 15:16:47,839 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:47,843 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:47,854 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:47,855 : - EPOCH - 19 : training on 330737 raw words (168144 effective words) took 0.9s, 191040 effective words/s\n",
      "2021-09-30 15:16:48,754 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:48,755 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:48,757 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:48,758 : - EPOCH - 20 : training on 330737 raw words (168350 effective words) took 0.9s, 189180 effective words/s\n",
      "2021-09-30 15:16:49,773 : - EPOCH 21 - PROGRESS: at 96.80% examples, 162645 words/s, in_qsize 2, out_qsize 1\n",
      "2021-09-30 15:16:49,775 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:49,777 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:49,781 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:49,782 : - EPOCH - 21 : training on 330737 raw words (168320 effective words) took 1.0s, 166469 effective words/s\n",
      "2021-09-30 15:16:50,682 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:50,683 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:50,699 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:50,700 : - EPOCH - 22 : training on 330737 raw words (168493 effective words) took 0.9s, 186138 effective words/s\n",
      "2021-09-30 15:16:51,563 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:51,572 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:51,597 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:51,598 : - EPOCH - 23 : training on 330737 raw words (168342 effective words) took 0.9s, 189787 effective words/s\n",
      "2021-09-30 15:16:52,473 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:52,475 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:52,483 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:52,484 : - EPOCH - 24 : training on 330737 raw words (168648 effective words) took 0.9s, 193048 effective words/s\n",
      "2021-09-30 15:16:53,318 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:53,322 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:53,341 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:53,342 : - EPOCH - 25 : training on 330737 raw words (168295 effective words) took 0.8s, 198351 effective words/s\n",
      "2021-09-30 15:16:54,184 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:54,194 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:54,209 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:54,210 : - EPOCH - 26 : training on 330737 raw words (168239 effective words) took 0.9s, 196368 effective words/s\n",
      "2021-09-30 15:16:55,055 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:55,062 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:55,069 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:55,070 : - EPOCH - 27 : training on 330737 raw words (167937 effective words) took 0.8s, 197624 effective words/s\n",
      "2021-09-30 15:16:55,909 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:55,931 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:55,945 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:55,946 : - EPOCH - 28 : training on 330737 raw words (168497 effective words) took 0.9s, 195150 effective words/s\n",
      "2021-09-30 15:16:56,803 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:56,808 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:56,829 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:56,830 : - EPOCH - 29 : training on 330737 raw words (168611 effective words) took 0.9s, 193195 effective words/s\n",
      "2021-09-30 15:16:57,672 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-30 15:16:57,685 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-30 15:16:57,694 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-30 15:16:57,695 : - EPOCH - 30 : training on 330737 raw words (168447 effective words) took 0.9s, 197213 effective words/s\n",
      "2021-09-30 15:16:57,695 : - Word2Vec lifecycle event {'msg': 'training on 9922110 raw words (5049557 effective words) took 28.3s, 178148 effective words/s', 'datetime': '2021-09-30T15:16:57.695645', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5049557, 9922110)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"maconha\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('maconhapesando', 0.5429049730300903),\n",
       " ('amaconha', 0.5263329744338989),\n",
       " ('macionha', 0.5222907066345215),\n",
       " ('machonha', 0.5155734419822693),\n",
       " ('macona', 0.5114761590957642),\n",
       " ('erva', 0.5063655376434326),\n",
       " ('maoonha', 0.5000309944152832),\n",
       " ('maconhaa', 0.4965268671512604),\n",
       " ('maconnha', 0.49501457810401917),\n",
       " ('maconhanha', 0.494768351316452)]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"crak\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('crack', 0.6502164602279663),\n",
       " ('ckack', 0.5305534601211548),\n",
       " ('gramns', 0.4862755537033081),\n",
       " ('cloração', 0.46918985247612),\n",
       " ('crcak', 0.4633367657661438),\n",
       " ('porcionadas', 0.4627552628517151),\n",
       " ('carck', 0.4623532295227051),\n",
       " ('grandede', 0.4570107161998749),\n",
       " ('fracionandas', 0.45640286803245544),\n",
       " ('suelem', 0.4558532238006592)]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"cocaina\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('cocaína', 0.6742475032806396),\n",
       " ('cocacina', 0.6040804386138916),\n",
       " ('cocaíana', 0.6026768684387207),\n",
       " ('cocina', 0.6005477905273438),\n",
       " ('cacaina', 0.5982316732406616),\n",
       " ('aspesto', 0.5962383151054382),\n",
       " ('cocaí', 0.5914677381515503),\n",
       " ('cocoaina', 0.5749762058258057),\n",
       " ('cociana', 0.573636531829834),\n",
       " ('cocainaa', 0.5570421814918518)]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"cacaina\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('subtsancia', 0.6784822940826416),\n",
       " ('aproximadamaente', 0.6469683647155762),\n",
       " ('àcrak', 0.6429532170295715),\n",
       " ('emmbaldas', 0.6352480053901672),\n",
       " ('tipica', 0.6292688846588135),\n",
       " ('cocina', 0.6280522346496582),\n",
       " ('duma', 0.6228322982788086),\n",
       " ('evolucron', 0.6214878559112549),\n",
       " ('totaldo', 0.6181179285049438),\n",
       " ('cocacina', 0.6118002533912659)]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"àcrak\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('cocainda', 0.9614291787147522),\n",
       " ('aproximdamante', 0.9243427515029907),\n",
       " ('subtsancia', 0.9156140685081482),\n",
       " ('denominadas', 0.9022440910339355),\n",
       " ('esmarelada', 0.9008833169937134),\n",
       " ('aproximadamented', 0.8714464902877808),\n",
       " ('emmbaldas', 0.8662444949150085),\n",
       " ('aproximadamentd', 0.8659058809280396),\n",
       " ('cigarritos', 0.8566253185272217),\n",
       " ('aproximadamaente', 0.8495968580245972)]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "w2v_modelo.wv.most_similar(\"àcrak\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('cocainda', 0.9451239109039307),\n",
       " ('esmarelada', 0.9037715792655945),\n",
       " ('aferilçao', 0.8924482464790344),\n",
       " ('qaurenta', 0.8648549318313599),\n",
       " ('toralizando', 0.8567660450935364),\n",
       " ('cocaica', 0.8491693735122681),\n",
       " ('caracteeisticas', 0.8359031081199646),\n",
       " ('commcaracteristica', 0.8236740827560425),\n",
       " ('flavia', 0.816604733467102),\n",
       " ('maconhanhah', 0.8155418634414673)]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "#w2v_modelo_sg.wv.save_word2vec_format('../Models/modelo_sg_drogas.txt', binary=False)\r\n",
    "#w2v_modelo.wv.save_word2vec_format('../Models/modelo_w2v_drogas.txt', binary=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-26 00:51:01,987 : - storing 8018x300 projection weights into ../Models/modelo_sg_drogas.txt\n",
      "2021-09-26 00:51:04,108 : - storing 8018x300 projection weights into ../Models/modelo_w2v_drogas.txt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "nlp = spacy.load('pt_core_news_lg', disable=['parser','ner','tagger','textcat'])\r\n",
    "\r\n",
    "def tokenizador(texto):\r\n",
    "    doc = nlp(texto)\r\n",
    "    tokens_validos = []\r\n",
    "    for token in doc:\r\n",
    "        e_valido = not token.is_stop and token.is_alpha\r\n",
    "        if e_valido:\r\n",
    "            tokens_validos.append(token.text.lower())\r\n",
    "\r\n",
    "    return tokens_validos\r\n",
    "\r\n",
    "texto = \"42 gramas de maconha apreendidos\"\r\n",
    "tokens = tokenizador(texto)\r\n",
    "print(tokens)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['gramas', 'maconha', 'apreendidos']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import numpy as np\r\n",
    "from gensim.models import KeyedVectors\r\n",
    "\r\n",
    "w2v_modelo_cbow = KeyedVectors.load_word2vec_format('../Models/modelo_w2v_drogas.txt')\r\n",
    "w2v_modelo_sg = KeyedVectors.load_word2vec_format('../Models/modelo_sg_drogas.txt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-30 15:32:30,633 : - loading projection weights from ../Models/modelo_w2v_drogas.txt\n",
      "2021-09-30 15:32:32,759 : - KeyedVectors lifecycle event {'msg': 'loaded (8018, 300) matrix of type float32 from ../Models/modelo_w2v_drogas.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-09-30T15:32:32.759350', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'load_word2vec_format'}\n",
      "2021-09-30 15:32:32,760 : - loading projection weights from ../Models/modelo_sg_drogas.txt\n",
      "2021-09-30 15:32:34,713 : - KeyedVectors lifecycle event {'msg': 'loaded (8018, 300) matrix of type float32 from ../Models/modelo_sg_drogas.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-09-30T15:32:34.713352', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:55:20) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def combinacao_de_vetores_por_soma(palavras, modelo):\r\n",
    "    \r\n",
    "    vetor_resultante = np.zeros((1, 300))\r\n",
    "    \r\n",
    "    for p in palavras:    \r\n",
    "        try:\r\n",
    "            vetor_resultante += modelo.get_vector(p)\r\n",
    "\r\n",
    "        except KeyError:\r\n",
    "           pass\r\n",
    "\r\n",
    "    return vetor_resultante\r\n",
    "\r\n",
    "\r\n",
    "vetor_texto = combinacao_de_vetores_por_soma(tokens, w2v_modelo_cbow)\r\n",
    "print(vetor_texto.shape)\r\n",
    "print(vetor_texto)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 300)\n",
      "[[ 0.1286815  -1.90977759  0.13999526  1.59192276 -0.75647955 -0.01888183\n",
      "   0.09412077 -0.1529047  -0.17223457  0.0638263  -0.10664336 -0.7182117\n",
      "  -0.54101728 -0.59995277 -0.22309858  0.45804346 -0.06492934 -0.66322355\n",
      "  -0.02955554  0.446263    1.27539738  1.01556657 -1.0327418   0.23260039\n",
      "   1.17448529 -1.13782222  1.96738273  0.17222127  0.85432186 -0.08431077\n",
      "   0.36445507  1.25217181  0.28909496 -0.81386827 -0.44321911 -0.87905075\n",
      "   0.85559136 -1.61212209 -0.21839337 -0.31124746 -0.12727931 -0.31963331\n",
      "   1.21662232  0.37635526  0.59015531  0.92955929 -1.36795782  0.10052644\n",
      "   0.21649069 -0.64006384  0.45780528  0.59258001  0.2170861   0.45159146\n",
      "  -0.76111618 -0.24482659  0.12455752 -0.57386573 -0.77144793  0.06450007\n",
      "   0.4309913   0.28348443  0.09103077 -2.0773297  -0.12554504 -0.07390217\n",
      "  -0.80918305 -0.30200598  0.28753987 -0.44278804  1.19332951 -1.11024354\n",
      "  -0.89336275 -0.75083446  0.70570676 -0.1603111  -0.12427431  0.53098689\n",
      "  -0.00523202 -0.04001921  1.53179658  0.98274198  1.02344102 -0.0893755\n",
      "   0.49384157  1.17892528  0.49644221  0.10014033 -1.35747977 -0.36565283\n",
      "   0.18547968 -0.87704973 -1.06421638 -0.03534937  0.23823948 -0.15316529\n",
      "  -1.00457332 -1.460352    1.62361151  0.33465984 -0.9391941   0.46791957\n",
      "   0.27947739 -0.17703247 -0.33902771  0.25677018 -1.10421205 -0.72112393\n",
      "  -0.25890754 -1.37035705 -0.91763827  0.45648165 -0.76407857  0.57376771\n",
      "  -0.91309426  0.51284205  1.03675111  0.58418345 -0.55105168  0.67738623\n",
      "  -0.17243102 -0.57882518  0.20062612 -1.14558452  0.06592008  1.14261402\n",
      "   0.08320199  1.4050096   0.63669258  1.14897728 -0.06970644 -0.40596208\n",
      "  -0.38905437 -0.19163066 -0.30931828  0.39347317 -0.11241939  0.43826278\n",
      "  -1.12516728  0.0780295   0.63122599 -1.10198248 -1.41418535  0.33675203\n",
      "  -0.49358217 -0.81626987 -0.19963858 -0.35333733 -0.35575703  0.34634131\n",
      "  -0.41739265 -0.89712636 -0.31059322 -0.79640286 -0.4588262   0.35253701\n",
      "  -0.30237782  0.41167472 -0.30102274  0.30136237  0.29564117 -0.37601603\n",
      "   0.32081807  0.38931298 -1.13124996 -0.36807436 -0.08822601  0.19047988\n",
      "  -0.32583105  0.21307376 -0.44521067 -0.09601012 -0.19173792  0.78989882\n",
      "   0.72514266  0.75813082 -0.24059806  1.89262687  0.17366767 -0.74977149\n",
      "  -0.86970451  0.03881905  1.30022031 -0.57178722  1.30104756  0.38651859\n",
      "   0.27567565  0.04495284  0.56541792  0.10710132 -0.95232785 -1.24879126\n",
      "   0.66832642 -1.56951758 -0.75350329  0.43712023 -0.75859177  0.09667397\n",
      "  -0.80083781 -0.79843007 -0.53267813 -0.25010836  0.3682771  -0.80760525\n",
      "  -0.74881119 -0.01508083  1.03421147  0.89758893 -0.63781327 -0.31916447\n",
      "  -1.26346129  1.09787251  0.82613775  0.54655623 -0.33603667  1.14440021\n",
      "  -1.12347417  1.30118523  0.08994759 -0.32040821 -0.00802359 -1.1678865\n",
      "   0.29913963  0.00869605  0.20706081 -0.3811001  -0.46420905  0.4597325\n",
      "  -0.68020302  0.1657238   1.06860761 -1.49956079 -0.66158136  0.41750655\n",
      "  -0.31084902 -0.63233131 -0.992461    1.43394765 -0.51164179  0.79990879\n",
      "  -0.05151647  0.18239968 -1.80866326  0.43205619  1.87691537 -0.49625817\n",
      "  -2.39457548  0.43619748 -2.04470912 -0.28639594  0.87221763  0.37545972\n",
      "   0.02713589 -0.14721932 -0.39281236 -0.79033007  0.81692478 -0.37587163\n",
      "  -1.48558483 -1.94702697  0.28066012 -0.92818211  0.07793648 -0.93072009\n",
      "  -0.73500178 -0.08413803  0.65660992  1.53514537  1.02990533 -0.30030927\n",
      "  -0.40061995 -0.13729325  0.77381523  0.60420857 -0.1107205   2.17249588\n",
      "  -0.35050061 -0.10432958 -0.26426267 -0.43219329  0.89932406 -0.82586701\n",
      "  -0.28149061 -0.25478441  0.6422634   0.44653499 -0.62718185 -0.99660838\n",
      "  -0.33510256  0.31902596  0.10156576 -0.46355671 -0.14023772 -0.36687241\n",
      "   0.64850703  0.64383753  0.44632487 -0.3725622   0.84239043 -1.26229899]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def matriz_vetores(textos, modelo):\r\n",
    "    #Numero de linhas da matriz depende do numero de linhas que eu quero vetorizar\r\n",
    "    x = len(textos)\r\n",
    "    #Numero de dimensoes\r\n",
    "    y = 300\r\n",
    "    matriz = np.zeros((x,y))\r\n",
    "\r\n",
    "    #Vetorizar meu texto\r\n",
    "    for i in range(x):\r\n",
    "        palavras = tokenizador(str(textos.iloc[i]))\r\n",
    "        matriz[i] = combinacao_de_vetores_por_soma(palavras, modelo)\r\n",
    "\r\n",
    "    return matriz\r\n",
    "\r\n",
    "\r\n",
    "tamanho_treino = len(titulos_tratados) * 0.8\r\n",
    "tamanho_teste = len(titulos_tratados) * 0.2\r\n",
    "\r\n",
    "matriz_vetores_treino_cbow = matriz_vetores(titulos_tratados.head(int(tamanho_treino)), w2v_modelo_cbow)\r\n",
    "matriz_vetores_teste_cbow = matriz_vetores(titulos_tratados.tail(int(tamanho_teste)), w2v_modelo_cbow)\r\n",
    "print(matriz_vetores_treino_cbow.shape)\r\n",
    "print(matriz_vetores_teste_cbow.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(41024, 300)\n",
      "(10256, 300)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def classificador(modelo, x_treino, y_treino, x_teste, y_teste):\r\n",
    "\r\n",
    "    RL = LogisticRegression(max_iter  = 800)\r\n",
    "    RL.fit(x_treino, y_treino)\r\n",
    "    \r\n",
    "    categorias = RL.predict(x_teste)\r\n",
    "    resultados = classification_report(y_teste, categorias)\r\n",
    "    \r\n",
    "    print(resultados)\r\n",
    "    return RL"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "frases =['Assisti um filme ótimo', 'Assisti um  filme péssimo']\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer(lowercase=False, max_features=50)\r\n",
    "\r\n",
    "caracteristicas = tfidf.fit_transform(frases)\r\n",
    "pd.DataFrame(\r\n",
    "        caracteristicas.todense(),\r\n",
    "        columns =  tfidf.get_feature_names()\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assisti</th>\n",
       "      <th>filme</th>\n",
       "      <th>péssimo</th>\n",
       "      <th>um</th>\n",
       "      <th>ótimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.630099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.630099</td>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Assisti     filme   péssimo        um     ótimo\n",
       "0  0.448321  0.448321  0.000000  0.448321  0.630099\n",
       "1  0.448321  0.448321  0.630099  0.448321  0.000000"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "dados_treino_not_na = dados_treino.dropna()\r\n",
    "dados_treino_drop_dup = dados_treino_not_na.drop_duplicates()\r\n",
    "dados_treino_drop_dup.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31209, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "regressaao_logistica1 = LogisticRegression(max_iter=100000)\r\n",
    "\r\n",
    "vetor_tf_idf_bruto =  tfidf.fit_transform(dados_treino_drop_dup.DESC_PADRAO)\r\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(vetor_tf_idf_bruto, \r\n",
    "                                                               dados_treino_drop_dup.RECLASSIFICAÇÃO,\r\n",
    "                                                               random_state=42)\r\n",
    "\r\n",
    "\r\n",
    "regressaao_logistica1.fit(treino,classe_treino)\r\n",
    "acuraria_vetor_tf_idf_bruto = regressaao_logistica1.score(teste, classe_teste)\r\n",
    "print(acuraria_vetor_tf_idf_bruto)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9416890939382289\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from nltk import ngrams\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer(lowercase=False, ngram_range  = (1,2))\r\n",
    "vetor_tfidf = tfidf.fit_transform(dados_treino_drop_dup.DESC_PADRAO)\r\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(vetor_tfidf, \r\n",
    "                                                               dados_treino_drop_dup.RECLASSIFICAÇÃO,\r\n",
    "                                                               random_state=42)\r\n",
    "\r\n",
    "regressaao_logistica2 = LogisticRegression(max_iter=100000)\r\n",
    "\r\n",
    "\r\n",
    "regressaao_logistica2.fit(treino, classe_treino)\r\n",
    "acuraria_vetor_tf_idf_ngrams = regressaao_logistica2.score(teste, classe_teste)\r\n",
    "print(acuraria_vetor_tf_idf_ngrams)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9443803665256952\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "pesos = pd.DataFrame(\r\n",
    "    regressaao_logistica2.coef_[0].T,\r\n",
    "    index =  tfidf.get_feature_names(),\r\n",
    ")\r\n",
    "\r\n",
    "pesos.nlargest(10,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cocaina</th>\n",
       "      <td>16.588675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de cocaina</th>\n",
       "      <td>7.796512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocaina pesando</th>\n",
       "      <td>5.226806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semelhante cocaina</th>\n",
       "      <td>5.017456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinos</th>\n",
       "      <td>2.949326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>po</th>\n",
       "      <td>2.709065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucha</th>\n",
       "      <td>2.023448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buchas</th>\n",
       "      <td>1.960289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocaina com</th>\n",
       "      <td>1.862976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocaina peso</th>\n",
       "      <td>1.831586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "cocaina             16.588675\n",
       "de cocaina           7.796512\n",
       "cocaina pesando      5.226806\n",
       "semelhante cocaina   5.017456\n",
       "pinos                2.949326\n",
       "po                   2.709065\n",
       "bucha                2.023448\n",
       "buchas               1.960289\n",
       "cocaina com          1.862976\n",
       "cocaina peso         1.831586"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "pesos = pd.DataFrame(\r\n",
    "    regressaao_logistica2.coef_[1].T,\r\n",
    "    index =  tfidf.get_feature_names(),\r\n",
    ")\r\n",
    "\r\n",
    "pesos.nlargest(10,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crack</th>\n",
       "      <td>15.774618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de crack</th>\n",
       "      <td>7.475729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crack pesando</th>\n",
       "      <td>4.870457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semelhante crack</th>\n",
       "      <td>4.548877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedras</th>\n",
       "      <td>4.018940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedra</th>\n",
       "      <td>3.082007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crak</th>\n",
       "      <td>2.610897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedras de</th>\n",
       "      <td>2.120847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedrinhas</th>\n",
       "      <td>1.885873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ao crack</th>\n",
       "      <td>1.709113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "crack             15.774618\n",
       "de crack           7.475729\n",
       "crack pesando      4.870457\n",
       "semelhante crack   4.548877\n",
       "pedras             4.018940\n",
       "pedra              3.082007\n",
       "crak               2.610897\n",
       "pedras de          2.120847\n",
       "pedrinhas          1.885873\n",
       "ao crack           1.709113"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "pesos = pd.DataFrame(\r\n",
    "    regressaao_logistica2.coef_[3].T,\r\n",
    "    index =  tfidf.get_feature_names(),\r\n",
    ")\r\n",
    "\r\n",
    "pesos.nlargest(10,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maconha</th>\n",
       "      <td>16.865359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de maconha</th>\n",
       "      <td>9.161756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semelhante maconha</th>\n",
       "      <td>5.900847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maconha pesando</th>\n",
       "      <td>5.822899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigarro</th>\n",
       "      <td>2.596435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maconha com</th>\n",
       "      <td>2.201777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tijolo</th>\n",
       "      <td>2.072743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maconha peso</th>\n",
       "      <td>2.042365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sativa</th>\n",
       "      <td>2.020073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar maconha</th>\n",
       "      <td>1.814834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "maconha             16.865359\n",
       "de maconha           9.161756\n",
       "semelhante maconha   5.900847\n",
       "maconha pesando      5.822899\n",
       "cigarro              2.596435\n",
       "maconha com          2.201777\n",
       "tijolo               2.072743\n",
       "maconha peso         2.042365\n",
       "sativa               2.020073\n",
       "similar maconha      1.814834"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "pesos = pd.DataFrame(\r\n",
    "    regressaao_logistica2.coef_[3].T,\r\n",
    "    index =  tfidf.get_feature_names(),\r\n",
    ")\r\n",
    "\r\n",
    "pesos.nsmallest(10,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cocaina</th>\n",
       "      <td>-8.314541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crack</th>\n",
       "      <td>-7.257624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de cocaina</th>\n",
       "      <td>-3.749380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de crack</th>\n",
       "      <td>-3.358985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedras</th>\n",
       "      <td>-2.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>po</th>\n",
       "      <td>-2.895967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocaina pesando</th>\n",
       "      <td>-2.568571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semelhante cocaina</th>\n",
       "      <td>-2.557396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinos</th>\n",
       "      <td>-2.288249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crack pesando</th>\n",
       "      <td>-2.284207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "cocaina            -8.314541\n",
       "crack              -7.257624\n",
       "de cocaina         -3.749380\n",
       "de crack           -3.358985\n",
       "pedras             -2.919711\n",
       "po                 -2.895967\n",
       "cocaina pesando    -2.568571\n",
       "semelhante cocaina -2.557396\n",
       "pinos              -2.288249\n",
       "crack pesando      -2.284207"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "pesos = pd.DataFrame(\r\n",
    "    regressaao_logistica2.coef_[2].T,\r\n",
    "    index =  tfidf.get_feature_names(),\r\n",
    ")\r\n",
    "\r\n",
    "pesos.nsmallest(10,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maconha</th>\n",
       "      <td>-5.950362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocaina</th>\n",
       "      <td>-4.749549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crack</th>\n",
       "      <td>-3.846809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de maconha</th>\n",
       "      <td>-3.264561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de cocaina</th>\n",
       "      <td>-2.282599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semelhante maconha</th>\n",
       "      <td>-2.190798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de crack</th>\n",
       "      <td>-2.046092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maconha pesando</th>\n",
       "      <td>-1.943689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aprox</th>\n",
       "      <td>-1.817330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>-1.629645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "maconha            -5.950362\n",
       "cocaina            -4.749549\n",
       "crack              -3.846809\n",
       "de maconha         -3.264561\n",
       "de cocaina         -2.282599\n",
       "semelhante maconha -2.190798\n",
       "de crack           -2.046092\n",
       "maconha pesando    -1.943689\n",
       "aprox              -1.817330\n",
       "de                 -1.629645"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "pesos = pd.DataFrame(\r\n",
    "    regressaao_logistica2.coef_[1].T,\r\n",
    "    index =  tfidf.get_feature_names(),\r\n",
    ")\r\n",
    "\r\n",
    "pesos.nsmallest(10,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maconha</th>\n",
       "      <td>-4.819093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocaina</th>\n",
       "      <td>-3.524585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de maconha</th>\n",
       "      <td>-2.720131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semelhante maconha</th>\n",
       "      <td>-1.863405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maconha pesando</th>\n",
       "      <td>-1.785699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de cocaina</th>\n",
       "      <td>-1.764533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esverdeada</th>\n",
       "      <td>-1.382249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigarro</th>\n",
       "      <td>-1.301423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erva</th>\n",
       "      <td>-1.266108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>po</th>\n",
       "      <td>-1.255079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "maconha            -4.819093\n",
       "cocaina            -3.524585\n",
       "de maconha         -2.720131\n",
       "semelhante maconha -1.863405\n",
       "maconha pesando    -1.785699\n",
       "de cocaina         -1.764533\n",
       "esverdeada         -1.382249\n",
       "cigarro            -1.301423\n",
       "erva               -1.266108\n",
       "po                 -1.255079"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "pesos = pd.DataFrame(\r\n",
    "    regressaao_logistica2.coef_[0].T,\r\n",
    "    index =  tfidf.get_feature_names(),\r\n",
    ")\r\n",
    "\r\n",
    "pesos.nsmallest(10,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maconha</th>\n",
       "      <td>-6.095904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crack</th>\n",
       "      <td>-4.670186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de maconha</th>\n",
       "      <td>-3.177064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maconha pesando</th>\n",
       "      <td>-2.093511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de crack</th>\n",
       "      <td>-2.070652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semelhante maconha</th>\n",
       "      <td>-1.846644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esverdeada</th>\n",
       "      <td>-1.834838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erva</th>\n",
       "      <td>-1.692627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedras</th>\n",
       "      <td>-1.643292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigarro</th>\n",
       "      <td>-1.634815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "maconha            -6.095904\n",
       "crack              -4.670186\n",
       "de maconha         -3.177064\n",
       "maconha pesando    -2.093511\n",
       "de crack           -2.070652\n",
       "semelhante maconha -1.846644\n",
       "esverdeada         -1.834838\n",
       "erva               -1.692627\n",
       "pedras             -1.643292\n",
       "cigarro            -1.634815"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "dab78f4d59ba6f70e46f434a1f395101b23afc19c4943827caa347c4a296b34f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}